{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "# Membership Inference over Diffusion-models-based Synthetic Tabular Data (MIDST) Challenge @ SaTML 2025.\n",
    "\n",
    "## White Box Single Table Competition\n",
    "Welcome to the MIDST challenge!\n",
    "\n",
    "The MIDST challenge is a series of competitions aiming to quantitatively evaluate the privacy of synthetic tabular data generated by diffusion models, with a specific focus on its resistance to membership inference attacks (MIAs).\n",
    "\n",
    "This particular competition focuses on White-box MIA on a single table transaction dataset.\n",
    "\n",
    "This notebook will walk you through the process of creating and packaging a submission to the white box single table challenge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "## Package Imports and Evironment Setup\n",
    "\n",
    "To start, lets import the required packages and define global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from typing import Callable, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from midst.data import get_challenge_points\n",
    "from midst.metrics import get_tpr_at_fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DATA_DIR = \"whitebox_single_table_tabddpm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Next, lets download and extract the data for the competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1BnwygJ8SVKGUCJ6OsexIVWDOdMCIy-DW\n",
      "From (redirected): https://drive.google.com/uc?id=1BnwygJ8SVKGUCJ6OsexIVWDOdMCIy-DW&confirm=t&uuid=8ca21d26-54af-49dc-be0a-6f7d8687c088\n",
      "To: /Users/johnjewell/Desktop/github/MIDST/starter_kits/whitebox_single_table_tabddpm.zip\n",
      "100%|████████████████████████████████████████| 958M/958M [00:44<00:00, 21.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1BnwygJ8SVKGUCJ6OsexIVWDOdMCIy-DW\n",
    "!unzip -qq -o whitebox_single_table_tabddpm.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcENY2HGV2Tx"
   },
   "source": [
    "### Contents\n",
    "\n",
    "The archive was extracted under the `whitebox_single_table_tabddpm` folder contains 3 subdirectories:\n",
    "\n",
    "- `train`: Models with metadata allowing to reconstruct their full training datasets. Use these to develop your attacks without having to train your own models.\n",
    "- `dev`: Models with metadata allowing to reconstruct just the set of challenge examples. Membership predictions for these challenges will be used to evaluate submissions during the competition and update the live scoreboard in CodaLab.\n",
    "- `eval`: Models with metadata allowing to reconstruct just the set of challenge examples. Membership predictions for these challenges will be used to evaluate submissions when the competition closes and to determine the final ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJRVZ-r9V2Tx"
   },
   "source": [
    "## Task\n",
    "\n",
    "Your task as a competitor is to produce, for each model in `dev` and `final`, a CSV file listing your confidence scores (values between 0 and 1) for the membership of the challenge examples. You must save these scores in a `prediction.csv` file and place it in the same folder as the corresponding model. A submission to the challenge is an an archive containing just these `prediction.csv` files.\n",
    "\n",
    "**You must submit predictions for both `dev` and `final` when you submit to CodaLab.**\n",
    "\n",
    "In the following, we will show you how to compute predictions from a basic membership inference attack and package them as a submission archive. To start, let's a create a baseline attack model using the provided training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zBNChV7ZV2Ty"
   },
   "outputs": [],
   "source": [
    "def get_attack_model(base_train_path: Path) -> Callable[[Any], float]:\n",
    "    return lambda x : random.uniform(0, 1)\n",
    "\n",
    "base_train_path = os.path.join(BASE_DATA_DIR, \"train\")\n",
    "attack_model = get_attack_model(base_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the attack model, we can obtain predictions for each point in the challenge point set for train, dev and eval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ar9drA4LV2Ty"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cebcf1af96343eb89f501c5a4fd07c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "phase:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08a16542aee34eaf84862771050e3a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4804e0b040884cad8ecaecafb0ff0445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f6db0b405145a6808f6912d89de02f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phases = [\"train\", \"dev\", \"eval\"]\n",
    "\n",
    "for phase in tqdm(phases, desc=\"phase\"):\n",
    "    root = os.path.join(BASE_DATA_DIR, phase)\n",
    "    for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "        path = os.path.join(root, model_folder)\n",
    "\n",
    "        challenge_points = get_challenge_points(path)\n",
    "\n",
    "        predictions = torch.Tensor([attack_model(cp) for cp in challenge_points])\n",
    "       \n",
    "        assert torch.all((0 <= predictions) & (predictions <= 1))\n",
    "        with open(os.path.join(path, \"prediction.csv\"), mode=\"w\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            # Write each value in a separate row\n",
    "            for value in list(predictions.numpy().squeeze()):\n",
    "                writer.writerow([value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGhGsrlPV2Ty"
   },
   "source": [
    "## Scoring\n",
    "\n",
    "Let's see how the attack does on `train`, for which we have the ground truth.\n",
    "When preparing a submission, you can use part of `train` to develop an attack and a held-out part to evaluate your attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-UN3zfuPV2Ty"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784271767452465da67b1379fd70a0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train TPR at FPR==10%: 0.09266666666666666\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "solutions  = []\n",
    "\n",
    "root = os.path.join(BASE_DATA_DIR, \"train\")\n",
    "for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "    path = os.path.join(root, model_folder)\n",
    "    predictions.append(np.loadtxt(os.path.join(path, \"prediction.csv\")))\n",
    "    solutions.append(np.loadtxt(os.path.join(path, \"challenge_label.csv\"), skiprows=1))\n",
    "\n",
    "predictions = np.concatenate(predictions)\n",
    "solutions = np.concatenate(solutions)\n",
    "\n",
    "tpr_at_fpr = get_tpr_at_fpr(solutions, predictions)\n",
    "\n",
    "print(f\"Train TPR at FPR==10%: {tpr_at_fpr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9LZ-EhfV2Ty"
   },
   "source": [
    "## Packaging the submission\n",
    "\n",
    "Now we can store the predictions into a zip file, which you can submit to CodaBench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ats5N4AoV2Tz"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f1ca4af1cb4e149d01bcfd0209c42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "phase:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bdb0794fdf46acaa380454b1ec8113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f77bd1ad5414c53a27d602e648b7c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "phases = ['dev', 'eval']\n",
    "\n",
    "with zipfile.ZipFile(\"predictions_whitebox_single_table_tabddpm.zip\", 'w') as zipf:\n",
    "        for phase in tqdm(phases, desc=\"phase\"):\n",
    "            root = os.path.join(BASE_DATA_DIR, phase)\n",
    "            for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "                path = os.path.join(root, model_folder)\n",
    "                file = os.path.join(path, \"prediction.csv\")\n",
    "                if os.path.exists(file):\n",
    "                    zipf.write(file)\n",
    "                else:\n",
    "                    raise FileNotFoundError(f\"`prediction.csv` not found in {path}. You need to provide predictions for all challenges\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c823568a0650a753a55947c22141ec594c2fc02bd68b5a71e505ecc57f17796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
