{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "# Membership Inference over Diffusion-models-based Synthetic Tabular Data (MIDST) Challenge @ SaTML 2025.\n",
    "\n",
    "## Black Single Table Competition\n",
    "Welcome to the MIDST challenge!\n",
    "\n",
    "The MIDST challenge is a series of competitions aiming to quantitatively evaluate the privacy of synthetic tabular data generated by diffusion models, with a specific focus on its resistance to membership inference attacks (MIAs).\n",
    "\n",
    "This particular competition focuses on Black Box MIA on a single table transaction dataset.\n",
    "\n",
    "This notebook will walk you through the process of creating and packaging a submission to the white box single table challenge. To start, let's download and extract the competition archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1FLMTDVDeGNR1falFR5d8nRWIXK1Wec1T\n",
      "From (redirected): https://drive.google.com/uc?id=1FLMTDVDeGNR1falFR5d8nRWIXK1Wec1T&confirm=t&uuid=87863f8c-dc90-4afc-bf66-2359e6ef0b3b\n",
      "To: /Users/johnjewell/Desktop/github/MIDST/starter_kits/blackbox_single_table_tabddpm.zip\n",
      "100%|████████████████████████████████████████| 960M/960M [00:54<00:00, 17.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1FLMTDVDeGNR1falFR5d8nRWIXK1Wec1T\n",
    "!unzip -qq -o blackbox_single_table_tabddpm.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcENY2HGV2Tx"
   },
   "source": [
    "## Contents\n",
    "\n",
    "The archive was extracted under the `blackbox_single_table_tabddpm` folder contains 3 subdirectories:\n",
    "\n",
    "- `train`: Training set of model along with output synthetic data. Use these to develop your attacks without having to train your own models.\n",
    "- `dev`: Set of challenge points. Membership predictions for these challenges will be used to evaluate submissions during the competition and update the live scoreboard in CodaBench.\n",
    "- `final`: Set of challenge points. Membership predictions for these challenges will be used to evaluate submissions when the competition closes and to determine the final ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJRVZ-r9V2Tx"
   },
   "source": [
    "## Task\n",
    "\n",
    "Your task as a competitor is to produce, for each model in `dev` and `final`, a CSV file listing your confidence scores (values between 0 and 1) for the membership of the challenge examples. You must save these scores in a `prediction.csv` file and place it in the same folder as the corresponding model. A submission to the challenge is an an archive containing just these `prediction.csv` files.\n",
    "\n",
    "**You must submit predictions for both `dev` and `final` when you submit to CodaBench.**\n",
    "\n",
    "In the following, we will show you how to compute predictions from a basic membership inference attack and package them as a submission archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zBNChV7ZV2Ty"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import csv\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from midst.data import get_features_and_labels\n",
    "\n",
    "def get_predictions(labels: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Placeholder function to generate predictions.\n",
    "    \"\"\"\n",
    "    return torch.rand(size=labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ar9drA4LV2Ty"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0105cccb023a4219b8d24aa0f2bc2ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "phase:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de3ef90542b24c7dac3644e267ed5c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d741fbf84f4b3f9d29eb2ffe361eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b5951c214c4b77a2c1dc3b82241eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BASE_DATA_DIR = \"blackbox_single_table_tabddpm\"\n",
    "phases = [\"train\", \"dev\", \"eval\"]\n",
    "\n",
    "for phase in tqdm(phases, desc=\"phase\"):\n",
    "    root = os.path.join(BASE_DATA_DIR, phase)\n",
    "    for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "        path = os.path.join(root, model_folder)\n",
    "\n",
    "        features, labels = get_features_and_labels(path)\n",
    "\n",
    "        predictions = get_predictions(labels)\n",
    "       \n",
    "        assert torch.all((0 <= predictions) & (predictions <= 1))\n",
    "        with open(os.path.join(path, \"prediction.csv\"), mode=\"w\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            # Write each value in a separate row\n",
    "            for value in list(predictions.numpy().squeeze()):\n",
    "                writer.writerow([value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGhGsrlPV2Ty"
   },
   "source": [
    "## Scoring\n",
    "\n",
    "Let's see how the attack does on `train`, for which we have the ground truth.\n",
    "When preparing a submission, you can use part of `train` to develop an attack and a held-out part to evaluate your attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-UN3zfuPV2Ty"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c18acc7cd382436a995ba3e88208f842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "phase:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c00bc157f6b414ea8bb768f22299246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from midst.metrics import get_tpr_at_fpr\n",
    "\n",
    "FPR_THRESHOLD = 0.1\n",
    "\n",
    "all_scores = {}\n",
    "phases = ['train']\n",
    "\n",
    "for phase in tqdm(phases, desc=\"phase\"):\n",
    "    predictions = []\n",
    "    solutions  = []\n",
    "\n",
    "    root = os.path.join(BASE_DATA_DIR, phase)\n",
    "    for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "        path = os.path.join(root, model_folder)\n",
    "        predictions.append(np.loadtxt(os.path.join(path, \"prediction.csv\")))\n",
    "        solutions.append(np.loadtxt(os.path.join(path, \"challenge_label.csv\"), skiprows=1))\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    solutions = np.concatenate(solutions)\n",
    "\n",
    "    tpr_at_fpr = get_tpr_at_fpr(solutions, predictions)\n",
    "    all_scores[phase] = tpr_at_fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9LZ-EhfV2Ty"
   },
   "source": [
    "## Packaging the submission\n",
    "\n",
    "Now we can store the predictions into a zip file, which you can submit to CodaBench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ats5N4AoV2Tz"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e99ef1e8eee2453cb8f62b7d024e5700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "phase:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac785b9ef481443389b58fbd0252c439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d9a947947049cba0769e1b4be5c6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "phases = ['dev', 'eval']\n",
    "\n",
    "with zipfile.ZipFile(\"predictions_blackbox_single_table_tabddpm.zip\", 'w') as zipf:\n",
    "        for phase in tqdm(phases, desc=\"phase\"):\n",
    "            root = os.path.join(BASE_DATA_DIR, phase)\n",
    "            for model_folder in tqdm(sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])), desc=\"model\"):\n",
    "                path = os.path.join(root, model_folder)\n",
    "                file = os.path.join(path, \"prediction.csv\")\n",
    "                if os.path.exists(file):\n",
    "                    zipf.write(file)\n",
    "                else:\n",
    "                    raise FileNotFoundError(f\"`prediction.csv` not found in {path}. You need to provide predictions for all challenges\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c823568a0650a753a55947c22141ec594c2fc02bd68b5a71e505ecc57f17796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
