{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "# Membership Inference over Diffusion-models-based Synthetic Tabular Data (MIDST) Challenge @ SaTML 2025.\n",
    "\n",
    "## Black Box Multi Table Competition\n",
    "Welcome to the MIDST challenge!\n",
    "\n",
    "The MIDST challenge is a multi-track competition aiming to quantitatively evaluate the privacy of synthetic tabular data generated by diffusion models, with a specific focus on its resistance to membership inference attacks (MIAs).\n",
    "\n",
    "This competition focuses on Black Box MIA on tabular diffusion models trained on a multi table transaction dataset. In particular, MIA will be explored over a state-of the art method Multi-relational Tabular Diffusion Model [ClavaDDPM](https://arxiv.org/abs/2405.17724). A collection of ClavaDDPM models will be trained on random subsets of the transaction dataset. The goal is to create an approach (MIA) that can distinguish between samples used to train a model (train data) and other data randomly sampled from the transaction dataset (holdout data) given only output synthetic data from the model. The `eval` set includes 10 models, each with its own set of challenge points (ie train and holdout data), to evaluate solutions on. To facilitate designing an attack, 30 `train` models are provided with comprehensive information about the model, training data and output synthetic data. Additionally, 10 `dev` models are provided to assist in evaluating the effectiveness of attacks prior to making a final submission to the `eval` set.\n",
    "\n",
    "This notebook will walk you through the process of creating and packaging a submission to the black box multi table challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "## Package Imports and Evironment Setup\n",
    "\n",
    "To start, lets import the required packages and define global variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "from typing import Callable, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from midst.data import get_challenge_points\n",
    "from midst.metrics import get_tpr_at_fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "CLAVADDPM_DATA_DIR = \"clavaddpm_black_box\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQ5My1aIV2Tv"
   },
   "source": [
    "## Data\n",
    "\n",
    "Next, lets download and extract the data for the competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MB3iIVMTFYyB"
   },
   "outputs": [],
   "source": [
    "# Download and unzip tabddpm data\n",
    "!gdown 1DfmnTnk-LlRXhePSfpUt_uY2DfkM5Wni\n",
    "!unzip -qq -o clavaddpm_black_box.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If there is an issue with the download (ie throttled for downloading too many files with gdown) you can simply download the zip manually from this [link](https://drive.google.com/file/d/1DfmnTnk-LlRXhePSfpUt_uY2DfkM5Wni/view?usp=drive_link) and extract it in the same directory this notebook exists."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NcENY2HGV2Tx",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Contents\n",
    "The archives extracted under the `black_box_clavaddpm` contain 3 subdirectories:\n",
    "\n",
    "- `train`: Comprehensive information (ie model weights+architecture, training data, output synthetic data etc.) about the set of shadow models. Use these to develop your attacks without having to train your own models.\n",
    "- `dev`: Set of challenge points. Membership predictions for these challenges will be used to evaluate submissions during the competition and update the live scoreboard in CodaBench.\n",
    "- `final`: Set of challenge points. Membership predictions for these challenges will be used to evaluate submissions when the competition closes and to determine the final ranking.\n",
    "\n",
    "<table> <tr> <th>Model Eval</th> <th>File Name</th> <th>Description</th> </tr> <!-- Black-Box Models - Train --> <tr> <td rowspan=\"36\"><strong>Black-Box Models - Train</strong></td> <td>account.csv</td> <td></td> </tr> <!-- Remaining Train data files --> <tr> <td>card.csv</td> <td></td> </tr> <tr> <td>client.csv</td> <td></td> </tr> <tr> <td>disp.csv</td> <td></td> </tr> <tr> <td>district.csv</td> <td></td> </tr> <tr> <td>loan.csv</td> <td></td> </tr> <tr> <td>order.csv</td> <td></td> </tr> <tr> <td>trans.csv</td> <td></td> </tr> <!-- Data domain files --> <tr> <td>account_domain.json</td> <td></td> </tr> <tr> <td>card_domain.json</td> <td></td> </tr> <tr> <td>client_domain.json</td> <td></td> </tr> <tr> <td>disp_domain.json</td> <td></td> </tr> <tr> <td>district_domain.json</td> <td></td> </tr> <tr> <td>loan_domain.json</td> <td></td> </tr> <tr> <td>order_domain.json</td> <td></td> </tr> <tr> <td>trans_domain.json</td> <td></td> </tr> <!-- Challenge data and labels --> <tr> <td>challenge_with_id.csv</td> <td></td> </tr> <tr> <td>challenge_label.csv</td> <td></td> </tr> <!-- Label encoders --> <tr> <td>account_label_encoders.pkl</td> <td></td> </tr> <tr> <td>card_label_encoders.pkl</td> <td></td> </tr> <tr> <td>client_label_encoders.pkl</td> <td></td> </tr> <tr> <td>disp_label_encoders.pkl</td> <td></td> </tr> <tr> <td>district_label_encoders.pkl</td> <td></td> </tr> <tr> <td>loan_label_encoders.pkl</td> <td></td> </tr> <tr> <td>order_label_encoders.pkl</td> <td></td> </tr> <tr> <td>trans_label_encoders.pkl</td> <td></td> </tr> <!-- Model checkpoints and other artifacts --> <tr> <td>workspace/train_1/cluster_ckpt.pkl</td> <td></td> </tr> <tr> <td>workspace/train_1/models/*</td> <td></td> </tr> <!-- Synthetic data --> <tr> <td>workspace/train_1/account/_final/account_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/card/_final/card_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/client/_final/client_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/disp/_final/disp_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/district/_final/district_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/loan/_final/loan_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/order/_final/order_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/trans/_final/trans_synthetic.csv</td> <td></td> </tr> <!-- Black-Box Models - Dev --> <tr> <td rowspan=\"9\"><strong>Black-Box Models - Dev</strong></td> <td>challenge_with_id.csv</td> <td></td> </tr> <!-- Synthetic data for Dev --> <tr> <td>workspace/train_1/account/_final/account_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/card/_final/card_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/client/_final/client_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/disp/_final/disp_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/district/_final/district_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/loan/_final/loan_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/order/_final/order_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/trans/_final/trans_synthetic.csv</td> <td></td> </tr> <!-- Black-Box Models - Eval --> <tr> <td rowspan=\"9\"><strong>Black-Box Models - Eval</strong></td> <td>challenge_with_id.csv</td> <td></td> </tr> <!-- Synthetic data for Eval --> <tr> <td>workspace/train_1/account/_final/account_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/card/_final/card_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/client/_final/client_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/disp/_final/disp_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/district/_final/district_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/loan/_final/loan_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/order/_final/order_synthetic.csv</td> <td></td> </tr> <tr> <td>workspace/train_1/trans/_final/trans_synthetic.csv</td> <td></td> </tr> </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJRVZ-r9V2Tx"
   },
   "source": [
    "## Task\n",
    "\n",
    "Your task as a competitor is to produce, for each model in `dev` and `final` in `tabddpm_black_box` and `tabsyn_black_box`, a CSV file listing your confidence scores (values between 0 and 1) for the membership of the challenge examples. You must save these scores in a `prediction.csv` file and place it in the same folder as the corresponding model. A submission to the challenge is an an archive containing just these `prediction.csv` files.\n",
    "\n",
    "**You must submit predictions for both `dev` and `final` when you submit to CodaBench.**\n",
    "\n",
    "In the following, we will show you how to compute predictions from a basic membership inference attack and package them as a submission archive. To start, let's create a baseline attack model `clavaddpm_attack_model` based on it's shadow (train) models: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zBNChV7ZV2Ty"
   },
   "outputs": [],
   "source": [
    "def get_attack_model(base_train_path: Path) -> Callable[[Any], float]:\n",
    "    return lambda x : random.uniform(0, 1)\n",
    "\n",
    "base_clavaddpm_train_path = os.path.join(CLAVADDPM_DATA_DIR, \"train\")\n",
    "clavaddpm_attack_model = get_attack_model(base_clavaddpm_train_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the attack model, we can obtain predictions for each point in the challenge point set for train, dev and eval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ar9drA4LV2Ty"
   },
   "outputs": [],
   "source": [
    "phases = [\"train\", \"dev\", \"eval\"]\n",
    "\n",
    "for base_dir, attack_model in zip([CLAVADDPM_DATA_DIR], [clavaddpm_attack_model]):\n",
    "    for phase in phases:\n",
    "        root = os.path.join(base_dir, phase)\n",
    "        for model_folder in sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])):\n",
    "            path = os.path.join(root, model_folder)\n",
    "    \n",
    "            challenge_points = get_challenge_points(path)\n",
    "    \n",
    "            predictions = torch.Tensor([attack_model(cp) for cp in challenge_points])\n",
    "           \n",
    "            assert torch.all((0 <= predictions) & (predictions <= 1))\n",
    "            with open(os.path.join(path, \"prediction.csv\"), mode=\"w\", newline=\"\") as file:\n",
    "                writer = csv.writer(file)\n",
    "    \n",
    "                # Write each value in a separate row\n",
    "                for value in list(predictions.numpy().squeeze()):\n",
    "                    writer.writerow([value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGhGsrlPV2Ty"
   },
   "source": [
    "## Scoring\n",
    "\n",
    "Let's see how the attack does on `train`, for which we have the ground truth.\n",
    "When preparing a submission, you can use part of `train` to develop an attack and a held-out part to evaluate your attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-UN3zfuPV2Ty"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clavaddpm Train Attack TPR at FPR==10%: 0.116\n",
      "Final Train Attack TPR at FPR==10%: 0.116\n"
     ]
    }
   ],
   "source": [
    "tpr_at_fpr_list = []\n",
    "for base_dir in [CLAVADDPM_DATA_DIR]:\n",
    "    predictions = []\n",
    "    solutions  = []\n",
    "    root = os.path.join(base_dir, \"train\")\n",
    "    for model_folder in sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])):\n",
    "        path = os.path.join(root, model_folder)\n",
    "        predictions.append(np.loadtxt(os.path.join(path, \"prediction.csv\")))\n",
    "        solutions.append(np.loadtxt(os.path.join(path, \"challenge_label.csv\"), skiprows=1))\n",
    "    \n",
    "    predictions = np.concatenate(predictions)\n",
    "    solutions = np.concatenate(solutions)\n",
    "    \n",
    "    tpr_at_fpr = get_tpr_at_fpr(solutions, predictions)\n",
    "    tpr_at_fpr_list.append(tpr_at_fpr)\n",
    "    \n",
    "    print(f\"{base_dir.split(\"_\")[0]} Train Attack TPR at FPR==10%: {tpr_at_fpr}\")\n",
    "\n",
    "final_tpr_at_fpr = max(tpr_at_fpr_list)\n",
    "print(f\"Final Train Attack TPR at FPR==10%: {final_tpr_at_fpr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M9LZ-EhfV2Ty"
   },
   "source": [
    "## Packaging the submission\n",
    "\n",
    "Now we can store the predictions into a zip file, which you can submit to CodaBench. We create seperate zip files for dev and eval. The structure of the submission is as follows:\n",
    "```\n",
    "└── root_folder\n",
    "    ├── clavaddpm_black_box\n",
    "       ├── dev\n",
    "       │   └── clavaddpm_#\n",
    "       │       └── prediction.csv\n",
    "       └── eval\n",
    "           └── clavaddpm_#\n",
    "                └── prediction.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ats5N4AoV2Tz"
   },
   "outputs": [],
   "source": [
    "for phase in [\"dev\", \"eval\"]:\n",
    "    with zipfile.ZipFile(f\"black_box_{phase}_multi_table_submission.zip\", 'w') as zipf:\n",
    "        for base_dir in [CLAVADDPM_DATA_DIR]:\n",
    "            root = os.path.join(base_dir, phase)\n",
    "            for model_folder in sorted(os.listdir(root), key=lambda d: int(d.split('_')[1])):\n",
    "                path = os.path.join(root, model_folder)\n",
    "                if not os.path.isdir(path): continue\n",
    "\n",
    "                file = os.path.join(path, \"prediction.csv\")\n",
    "                if os.path.exists(file):\n",
    "                    # Use `arcname` to remove the base directory and phase directory from the zip path\n",
    "                    arcname = os.path.relpath(file, os.path.dirname(base_dir))\n",
    "                    zipf.write(file, arcname=arcname)\n",
    "                else:\n",
    "                    raise FileNotFoundError(f\"`prediction.csv` not found in {path}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated black_box_dev_submission.zip and black_box_eval_submission.zip can be used to directly submit to the respective phases in the CodaBench UI."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1c823568a0650a753a55947c22141ec594c2fc02bd68b5a71e505ecc57f17796"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
